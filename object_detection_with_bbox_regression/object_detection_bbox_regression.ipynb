{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff6eae0e",
   "metadata": {},
   "source": [
    "### The idea is very intuitive. we will train a n/w that will predict bbox coordinates along with the probability score of the class of object in the image\n",
    "### when we train a image classifier , we input an image and get probability score as output \n",
    "### when we train a detector we will input and image and get along with the probability score , 4 more values representing top left and bottom right (x,y).\n",
    "### we will have a base n/w for extracting features and two branches one for classification , other for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f495d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "#from pyimagesearch import config\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacac370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55075771",
   "metadata": {},
   "outputs": [],
   "source": [
    "### importing the resnet model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a8296b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_to_label={\"dolphin\":0,\"helicopter\":1,\"panda\":2}\n",
    "num_classes=len(classes_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d113691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the VGG16 network, ensuring the head FC layers are left off\n",
    "vgg = VGG16(weights=\"imagenet\", include_top=False,\n",
    "\tinput_tensor=Input(shape=(224, 224, 3)))\n",
    "# freeze all VGG layers so they will *not* be updated during the\n",
    "# training process\n",
    "vgg.trainable = False\n",
    "# flatten the max-pooling output of VGG\n",
    "flatten = vgg.output\n",
    "flatten = Flatten()(flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce59393a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45f38c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a fully-connected layer header to output the predicted\n",
    "# bounding box coordinates\n",
    "bboxHead = Dense(128, activation=\"relu\")(flatten)\n",
    "bboxHead = Dense(64, activation=\"relu\")(bboxHead)\n",
    "bboxHead = Dense(32, activation=\"relu\")(bboxHead)\n",
    "bboxHead = Dense(4, activation=\"sigmoid\",\n",
    "\tname=\"bounding_box\")(bboxHead)\n",
    "# construct a second fully-connected layer head, this one to predict\n",
    "# the class label\n",
    "softmaxHead = Dense(512, activation=\"relu\")(flatten)\n",
    "softmaxHead = Dropout(0.5)(softmaxHead)\n",
    "softmaxHead = Dense(512, activation=\"relu\")(softmaxHead)\n",
    "softmaxHead = Dropout(0.5)(softmaxHead)\n",
    "softmaxHead = Dense(num_classes, activation=\"softmax\",\n",
    "\tname=\"class_label\")(softmaxHead)\n",
    "# put together our model which accept an input image and then output\n",
    "# bounding box coordinates and a class label\n",
    "model = Model(\n",
    "\tinputs=vgg.input,\n",
    "\toutputs=(bboxHead, softmaxHead))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "749e4779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "580b53c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)          (None, 224, 224, 64  1792        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)          (None, 224, 224, 64  36928       ['block1_conv1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_pool (MaxPooling2D)     (None, 112, 112, 64  0           ['block1_conv2[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block2_conv1 (Conv2D)          (None, 112, 112, 12  73856       ['block1_pool[0][0]']            \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block2_conv2 (Conv2D)          (None, 112, 112, 12  147584      ['block2_conv1[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block2_pool (MaxPooling2D)     (None, 56, 56, 128)  0           ['block2_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv1 (Conv2D)          (None, 56, 56, 256)  295168      ['block2_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block3_conv2 (Conv2D)          (None, 56, 56, 256)  590080      ['block3_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv3 (Conv2D)          (None, 56, 56, 256)  590080      ['block3_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block3_pool (MaxPooling2D)     (None, 28, 28, 256)  0           ['block3_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv1 (Conv2D)          (None, 28, 28, 512)  1180160     ['block3_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block4_conv2 (Conv2D)          (None, 28, 28, 512)  2359808     ['block4_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv3 (Conv2D)          (None, 28, 28, 512)  2359808     ['block4_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block4_pool (MaxPooling2D)     (None, 14, 14, 512)  0           ['block4_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv1 (Conv2D)          (None, 14, 14, 512)  2359808     ['block4_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block5_conv2 (Conv2D)          (None, 14, 14, 512)  2359808     ['block5_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv3 (Conv2D)          (None, 14, 14, 512)  2359808     ['block5_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block5_pool (MaxPooling2D)     (None, 7, 7, 512)    0           ['block5_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 25088)        0           ['block5_pool[0][0]']            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 512)          12845568    ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          3211392     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 512)          0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           8256        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 512)          262656      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 32)           2080        ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 512)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " bounding_box (Dense)           (None, 4)            132         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " class_label (Dense)            (None, 3)            1539        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,046,311\n",
      "Trainable params: 16,331,623\n",
      "Non-trainable params: 14,714,688\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uid38717\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# define a dictionary to set the loss methods -- categorical\n",
    "# cross-entropy for the class label head and mean absolute error\n",
    "# for the bounding box head\n",
    "losses = {\"class_label\": \"categorical_crossentropy\",\"bounding_box\": \"mean_squared_error\",}\n",
    "# define a dictionary that specifies the weights per loss (both the\n",
    "# class label and bounding box outputs will receive equal weight)\n",
    "lossWeights = {\"class_label\": 1.0,\"bounding_box\": 1.0}\n",
    "# initialize the optimizer, compile the model, and show the model\n",
    "# summary\n",
    "opt = Adam(lr=0.001)\n",
    "model.compile(loss=losses, optimizer=opt, metrics=[\"accuracy\"], loss_weights=lossWeights)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca366f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.utils.vis_utils import plot_model\n",
    "#plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bdf28a",
   "metadata": {},
   "source": [
    "#### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253ee021",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data_path=r\"D:\\LearningObjectDetection\\data\\catltech-101_mini\"\n",
    "base_ann_path=os.path.join(base_data_path,\"annotations\")\n",
    "base_img_path=os.path.join(base_data_path,\"images\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
