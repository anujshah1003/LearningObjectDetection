{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90d23765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60f92e3",
   "metadata": {},
   "source": [
    "### The RCNN consists of this major steps\n",
    "1. Use selctive srach to propose Regions\n",
    "2. Get the CNN features of this proopses regions unsig a pretrained CNN\n",
    "3. Train a classifier on this CNN features for (K+1) classes, K is the number of object and 1 is the background class\n",
    "    -  Prepare positive and negative sample to train the classifier\n",
    "4. To reduce localization error train a regression model to predict the correct offset (BBox Ofset regressor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b736ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os,sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cea9a669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d159733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_path=r'D:\\LearningObjectDetection'\n",
    "sys.path.append(parent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21ea5a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.20.3\n",
      "1.5.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import utils\n",
    "print(np.__version__)\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f460c350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['raccoon_labels.csv', 'test.record', 'test_labels.csv', 'train.record', 'train_labels.csv']\n"
     ]
    }
   ],
   "source": [
    "base_data_path=r\"D:\\LearningObjectDetection\\data\\raccoon_dataset\"\n",
    "base_ann_path=os.path.join(base_data_path,\"data\")\n",
    "base_img_path=os.path.join(base_data_path,\"images\")\n",
    "print(os.listdir(base_ann_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afae810d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         filename  width  height    class  xmin  ymin  xmax  ymax\n",
      "0  raccoon-17.jpg    259     194  raccoon    95    60   167   118\n",
      "1  raccoon-11.jpg    660     432  raccoon     3     1   461   431\n",
      "2  raccoon-63.jpg    600     400  raccoon    74   107   280   290\n",
      "3  raccoon-63.jpg    600     400  raccoon   227    93   403   298\n",
      "4  raccoon-60.jpg    273     185  raccoon    58    33   197   127\n",
      "          filename  width  height    class  xmin  ymin  xmax  ymax\n",
      "0  raccoon-146.jpg    275     183  raccoon     4     4   271   180\n",
      "1  raccoon-105.jpg    720     960  raccoon   250    49   714   869\n",
      "2  raccoon-143.jpg    259     194  raccoon    17    29   238   162\n",
      "3   raccoon-57.jpg    640     425  raccoon    82     6   638   423\n",
      "4   raccoon-68.jpg    640     423  raccoon     1    24   517   423\n"
     ]
    }
   ],
   "source": [
    "train_df=pd.read_csv(os.path.join(base_ann_path,\"train_labels.csv\"))\n",
    "test_df=pd.read_csv(os.path.join(base_ann_path,\"test_labels.csv\"))\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5f59d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 60 167 118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_name=\"raccoon-17.jpg\"\n",
    "img_path=os.path.join(base_img_path,img_name)\n",
    "img=cv2.imread(img_path)\n",
    "box_coord=train_df[train_df['filename']==img_name]\n",
    "#print(box_coord)\n",
    "x1,y1,x2,y2 = box_coord.xmin[0],box_coord.ymin[0],box_coord.xmax[0],box_coord.ymax[0]\n",
    "print(x1,y1,x2,y2)\n",
    "img_rect=cv2.rectangle(img.copy(),(x1,y1),(x2,y2),color=(255,0,0))\n",
    "#cv2.imshow(\"img\",img)\n",
    "cv2.imshow(\"img_rect\",img_rect)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9779aba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our output class label directories\n",
    "prepared_data_path = os.path.join(base_data_path, \"prepared_data\")\n",
    "positive_path = os.path.join(*[prepared_data_path, \"raccoon_test\"])\n",
    "negative_path = os.path.join(*[prepared_data_path, \"no_raccoon_test\"])\n",
    "# loop over the output positive and negative directories\n",
    "for dir_path in (positive_path, negative_path):\n",
    "    # if the output directory does not exist yet, create it\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7756cb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the number of max proposals used when running selective\n",
    "# search for (1) gathering training data and (2) performing inference\n",
    "max_proposals = 2000\n",
    "max_proposals_infer = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b6083ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the maximum number of positive and negative images to be\n",
    "# generated from each image\n",
    "max_positive = 30\n",
    "max_negative = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ede8aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining positive an dnegatice ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47b306a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first lest get our ROIs using selective search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56893702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab all image paths in the input images directory\n",
    "img_names = os.listdir(base_img_path)\n",
    "# initialize the total number of positive and negative images we have\n",
    "# saved to disk so far\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "051b19c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dims=(224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f21bcca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processing image 1/200...\n",
      "0\n",
      "[INFO] processing image 2/200...\n",
      "0\n",
      "[INFO] processing image 3/200...\n",
      "0\n",
      "[INFO] processing image 4/200...\n",
      "0\n",
      "[INFO] processing image 5/200...\n",
      "0\n",
      "[INFO] processing image 6/200...\n",
      "0\n",
      "[INFO] processing image 7/200...\n",
      "0\n",
      "[INFO] processing image 8/200...\n",
      "1\n",
      "[INFO] processing image 9/200...\n",
      "1\n",
      "[INFO] processing image 10/200...\n",
      "0\n",
      "[INFO] processing image 11/200...\n",
      "0\n",
      "[INFO] processing image 12/200...\n",
      "0\n",
      "[INFO] processing image 13/200...\n",
      "0\n",
      "[INFO] processing image 14/200...\n",
      "1\n",
      "[INFO] processing image 15/200...\n",
      "0\n",
      "[INFO] processing image 16/200...\n",
      "0\n",
      "[INFO] processing image 17/200...\n",
      "0\n",
      "[INFO] processing image 18/200...\n",
      "0\n",
      "[INFO] processing image 19/200...\n",
      "0\n",
      "[INFO] processing image 20/200...\n",
      "0\n",
      "[INFO] processing image 21/200...\n",
      "0\n",
      "[INFO] processing image 22/200...\n",
      "0\n",
      "[INFO] processing image 23/200...\n",
      "0\n",
      "[INFO] processing image 24/200...\n",
      "0\n",
      "[INFO] processing image 25/200...\n",
      "0\n",
      "[INFO] processing image 26/200...\n",
      "0\n",
      "[INFO] processing image 27/200...\n",
      "0\n",
      "[INFO] processing image 28/200...\n",
      "0\n",
      "[INFO] processing image 29/200...\n",
      "0\n",
      "[INFO] processing image 30/200...\n",
      "1\n",
      "[INFO] processing image 31/200...\n",
      "1\n",
      "[INFO] processing image 32/200...\n",
      "1\n",
      "[INFO] processing image 33/200...\n",
      "1\n",
      "[INFO] processing image 34/200...\n",
      "1\n",
      "[INFO] processing image 35/200...\n",
      "0\n",
      "[INFO] processing image 36/200...\n",
      "0\n",
      "[INFO] processing image 37/200...\n",
      "0\n",
      "[INFO] processing image 38/200...\n",
      "0\n",
      "[INFO] processing image 39/200...\n",
      "0\n",
      "[INFO] processing image 40/200...\n",
      "1\n",
      "[INFO] processing image 41/200...\n",
      "0\n",
      "[INFO] processing image 42/200...\n",
      "0\n",
      "[INFO] processing image 43/200...\n",
      "0\n",
      "[INFO] processing image 44/200...\n",
      "0\n",
      "[INFO] processing image 45/200...\n",
      "0\n",
      "[INFO] processing image 46/200...\n",
      "1\n",
      "[INFO] processing image 47/200...\n",
      "1\n",
      "[INFO] processing image 48/200...\n",
      "0\n",
      "[INFO] processing image 49/200...\n",
      "0\n",
      "[INFO] processing image 50/200...\n",
      "1\n",
      "[INFO] processing image 51/200...\n",
      "1\n",
      "[INFO] processing image 52/200...\n",
      "2\n",
      "[INFO] processing image 53/200...\n",
      "1\n",
      "[INFO] processing image 54/200...\n",
      "0\n",
      "[INFO] processing image 55/200...\n",
      "0\n",
      "[INFO] processing image 56/200...\n",
      "0\n",
      "[INFO] processing image 57/200...\n",
      "0\n",
      "[INFO] processing image 58/200...\n",
      "0\n",
      "[INFO] processing image 59/200...\n",
      "0\n",
      "[INFO] processing image 60/200...\n",
      "0\n",
      "[INFO] processing image 61/200...\n",
      "0\n",
      "[INFO] processing image 62/200...\n",
      "0\n",
      "[INFO] processing image 63/200...\n",
      "0\n",
      "[INFO] processing image 64/200...\n",
      "1\n",
      "[INFO] processing image 65/200...\n",
      "0\n",
      "[INFO] processing image 66/200...\n",
      "1\n",
      "[INFO] processing image 67/200...\n",
      "0\n",
      "[INFO] processing image 68/200...\n",
      "0\n",
      "[INFO] processing image 69/200...\n",
      "0\n",
      "[INFO] processing image 70/200...\n",
      "0\n",
      "[INFO] processing image 71/200...\n",
      "0\n",
      "[INFO] processing image 72/200...\n",
      "0\n",
      "[INFO] processing image 73/200...\n",
      "1\n",
      "[INFO] processing image 74/200...\n",
      "0\n",
      "[INFO] processing image 75/200...\n",
      "0\n",
      "[INFO] processing image 76/200...\n",
      "0\n",
      "[INFO] processing image 77/200...\n",
      "2\n",
      "[INFO] processing image 78/200...\n",
      "0\n",
      "[INFO] processing image 79/200...\n",
      "0\n",
      "[INFO] processing image 80/200...\n",
      "0\n",
      "[INFO] processing image 81/200...\n",
      "0\n",
      "[INFO] processing image 82/200...\n",
      "0\n",
      "[INFO] processing image 83/200...\n",
      "0\n",
      "[INFO] processing image 84/200...\n",
      "0\n",
      "[INFO] processing image 85/200...\n",
      "0\n",
      "[INFO] processing image 86/200...\n",
      "2\n",
      "[INFO] processing image 87/200...\n",
      "0\n",
      "[INFO] processing image 88/200...\n",
      "0\n",
      "[INFO] processing image 89/200...\n",
      "0\n",
      "[INFO] processing image 90/200...\n",
      "0\n",
      "[INFO] processing image 91/200...\n",
      "0\n",
      "[INFO] processing image 92/200...\n",
      "1\n",
      "[INFO] processing image 93/200...\n",
      "0\n",
      "[INFO] processing image 94/200...\n",
      "0\n",
      "[INFO] processing image 95/200...\n",
      "0\n",
      "[INFO] processing image 96/200...\n",
      "1\n",
      "[INFO] processing image 97/200...\n",
      "1\n",
      "[INFO] processing image 98/200...\n",
      "0\n",
      "[INFO] processing image 99/200...\n",
      "0\n",
      "[INFO] processing image 100/200...\n",
      "1\n",
      "[INFO] processing image 101/200...\n",
      "0\n",
      "[INFO] processing image 102/200...\n",
      "0\n",
      "[INFO] processing image 103/200...\n",
      "0\n",
      "[INFO] processing image 104/200...\n",
      "1\n",
      "[INFO] processing image 105/200...\n",
      "0\n",
      "[INFO] processing image 106/200...\n",
      "0\n",
      "[INFO] processing image 107/200...\n",
      "0\n",
      "[INFO] processing image 108/200...\n",
      "0\n",
      "[INFO] processing image 109/200...\n",
      "1\n",
      "[INFO] processing image 110/200...\n",
      "0\n",
      "[INFO] processing image 111/200...\n",
      "0\n",
      "[INFO] processing image 112/200...\n",
      "0\n",
      "[INFO] processing image 113/200...\n",
      "0\n",
      "[INFO] processing image 114/200...\n",
      "0\n",
      "[INFO] processing image 115/200...\n",
      "0\n",
      "[INFO] processing image 116/200...\n",
      "0\n",
      "[INFO] processing image 117/200...\n",
      "0\n",
      "[INFO] processing image 118/200...\n",
      "0\n",
      "[INFO] processing image 119/200...\n",
      "0\n",
      "[INFO] processing image 120/200...\n",
      "0\n",
      "[INFO] processing image 121/200...\n",
      "1\n",
      "[INFO] processing image 122/200...\n",
      "1\n",
      "[INFO] processing image 123/200...\n",
      "1\n",
      "[INFO] processing image 124/200...\n",
      "0\n",
      "[INFO] processing image 125/200...\n",
      "0\n",
      "[INFO] processing image 126/200...\n",
      "0\n",
      "[INFO] processing image 127/200...\n",
      "0\n",
      "[INFO] processing image 128/200...\n",
      "0\n",
      "[INFO] processing image 129/200...\n",
      "0\n",
      "[INFO] processing image 130/200...\n",
      "0\n",
      "[INFO] processing image 131/200...\n",
      "0\n",
      "[INFO] processing image 132/200...\n",
      "0\n",
      "[INFO] processing image 133/200...\n",
      "0\n",
      "[INFO] processing image 134/200...\n",
      "0\n",
      "[INFO] processing image 135/200...\n",
      "0\n",
      "[INFO] processing image 136/200...\n",
      "1\n",
      "[INFO] processing image 137/200...\n",
      "1\n",
      "[INFO] processing image 138/200...\n",
      "0\n",
      "[INFO] processing image 139/200...\n",
      "0\n",
      "[INFO] processing image 140/200...\n",
      "0\n",
      "[INFO] processing image 141/200...\n",
      "0\n",
      "[INFO] processing image 142/200...\n",
      "0\n",
      "[INFO] processing image 143/200...\n",
      "0\n",
      "[INFO] processing image 144/200...\n",
      "0\n",
      "[INFO] processing image 145/200...\n",
      "0\n",
      "[INFO] processing image 146/200...\n",
      "1\n",
      "[INFO] processing image 147/200...\n",
      "0\n",
      "[INFO] processing image 148/200...\n",
      "0\n",
      "[INFO] processing image 149/200...\n",
      "0\n",
      "[INFO] processing image 150/200...\n",
      "0\n",
      "[INFO] processing image 151/200...\n",
      "0\n",
      "[INFO] processing image 152/200...\n",
      "0\n",
      "[INFO] processing image 153/200...\n",
      "0\n",
      "[INFO] processing image 154/200...\n",
      "1\n",
      "[INFO] processing image 155/200...\n",
      "0\n",
      "[INFO] processing image 156/200...\n",
      "1\n",
      "[INFO] processing image 157/200...\n",
      "0\n",
      "[INFO] processing image 158/200...\n",
      "0\n",
      "[INFO] processing image 159/200...\n",
      "0\n",
      "[INFO] processing image 160/200...\n",
      "1\n",
      "[INFO] processing image 161/200...\n",
      "0\n",
      "[INFO] processing image 162/200...\n",
      "0\n",
      "[INFO] processing image 163/200...\n",
      "0\n",
      "[INFO] processing image 164/200...\n",
      "0\n",
      "[INFO] processing image 165/200...\n",
      "0\n",
      "[INFO] processing image 166/200...\n",
      "1\n",
      "[INFO] processing image 167/200...\n",
      "0\n",
      "[INFO] processing image 168/200...\n",
      "0\n",
      "[INFO] processing image 169/200...\n",
      "0\n",
      "[INFO] processing image 170/200...\n",
      "0\n",
      "[INFO] processing image 171/200...\n",
      "2\n",
      "[INFO] processing image 172/200...\n",
      "0\n",
      "[INFO] processing image 173/200...\n",
      "0\n",
      "[INFO] processing image 174/200...\n",
      "0\n",
      "[INFO] processing image 175/200...\n",
      "0\n",
      "[INFO] processing image 176/200...\n",
      "0\n",
      "[INFO] processing image 177/200...\n",
      "0\n",
      "[INFO] processing image 178/200...\n",
      "0\n",
      "[INFO] processing image 179/200...\n",
      "1\n",
      "[INFO] processing image 180/200...\n",
      "0\n",
      "[INFO] processing image 181/200...\n",
      "0\n",
      "[INFO] processing image 182/200...\n",
      "0\n",
      "[INFO] processing image 183/200...\n",
      "0\n",
      "[INFO] processing image 184/200...\n",
      "0\n",
      "[INFO] processing image 185/200...\n",
      "0\n",
      "[INFO] processing image 186/200...\n",
      "0\n",
      "[INFO] processing image 187/200...\n",
      "0\n",
      "[INFO] processing image 188/200...\n",
      "0\n",
      "[INFO] processing image 189/200...\n",
      "0\n",
      "[INFO] processing image 190/200...\n",
      "0\n",
      "[INFO] processing image 191/200...\n",
      "0\n",
      "[INFO] processing image 192/200...\n",
      "0\n",
      "[INFO] processing image 193/200...\n",
      "0\n",
      "[INFO] processing image 194/200...\n",
      "0\n",
      "[INFO] processing image 195/200...\n",
      "0\n",
      "[INFO] processing image 196/200...\n",
      "1\n",
      "[INFO] processing image 197/200...\n",
      "0\n",
      "[INFO] processing image 198/200...\n",
      "0\n",
      "[INFO] processing image 199/200...\n",
      "0\n",
      "[INFO] processing image 200/200...\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "total_positive = 0\n",
    "total_negative = 0\n",
    "# loop over the image paths\n",
    "for (i, img_name) in enumerate(img_names):\n",
    "    # show a progress report\n",
    "    print(\"[INFO] processing image {}/{}...\".format(i + 1,len(img_names)))\n",
    "    img_path=os.path.join(base_img_path,img_name)\n",
    "    #ann_df=train_df[train_df['filename']==img_name]\n",
    "    ann_df=test_df[test_df['filename']==img_name]\n",
    "\n",
    "    print(len(ann_df))\n",
    "    gt_boxes=[]\n",
    "    for idx,row in ann_df.iterrows():\n",
    "        x1,y1,x2,y2=row.xmin,row.ymin,row.xmax,row.ymax\n",
    "        #print(x1,y1,x2,y2)\n",
    "        gt_boxes.append((x1,y1,x2,y2))\n",
    "    # load the input image from disk\n",
    "    image = cv2.imread(img_path)\n",
    "    \n",
    "    # run selective search on the image and initialize our list of\n",
    "    # proposed boxes\n",
    "    ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "    ss.setBaseImage(image)\n",
    "    ss.switchToSelectiveSearchFast()\n",
    "    rects = ss.process()\n",
    "    proposed_rects= []\n",
    "    # loop over the rectangles generated by selective search\n",
    "    for (x, y, w, h) in rects:\n",
    "        # convert our bounding boxes from (x, y, w, h) to (startX,\n",
    "        # startY, startX, endY)\n",
    "        proposed_rects.append((x, y, x + w, y + h))\n",
    "        \n",
    "    # initialize counters used to count the number of positive and\n",
    "    # negative ROIs saved thus far\n",
    "    positive_ROIs = 0\n",
    "    negative_ROIs = 0\n",
    "    # loop over the maximum number of region proposals\n",
    "    for proposed_rect in proposed_rects[:max_proposals]:\n",
    "        # unpack the proposed rectangle bounding box\n",
    "        (prop_x1, prop_y1, prop_x2, prop_y2) = proposed_rect\n",
    "        # loop over the ground-truth bounding boxes\n",
    "        for gt_box in gt_boxes:\n",
    "            # compute the intersection over union between the two\n",
    "            # boxes and unpack the ground-truth bounding box\n",
    "            iou = utils.IOU(gt_box, proposed_rect)\n",
    "            (gt_x1, gt_y1, gt_x2,gt_y2) = gt_box\n",
    "            # initialize the ROI and output path\n",
    "            roi = None\n",
    "            output_path = None\n",
    "            \n",
    "            # check to see if the IOU is greater than 70% *and* that\n",
    "            # we have not hit our positive count limit\n",
    "            if iou > 0.8 and positive_ROIs <= max_positive:\n",
    "                # extract the ROI and then derive the output path to\n",
    "                # the positive instance\n",
    "                roi = image[prop_y1:prop_y2, prop_x1:prop_x2]\n",
    "                filename = \"{}.png\".format(total_positive)\n",
    "                outputPath = os.path.join(*[positive_path,filename])\n",
    "                # increment the positive counters\n",
    "                positive_ROIs += 1\n",
    "                total_positive += 1\n",
    "            # determine if the proposed bounding box falls *within*\n",
    "            # the ground-truth bounding box\n",
    "            fullOverlap = prop_x1 >= gt_x1\n",
    "            fullOverlap = fullOverlap and prop_y1 >= gt_y1\n",
    "            fullOverlap = fullOverlap and prop_x2 <= gt_y2\n",
    "            fullOverlap = fullOverlap and prop_y2 <= gt_y2\n",
    "            \n",
    "            # check to see if there is not full overlap *and* the IoU\n",
    "            # is less than 5% *and* we have not hit our negative\n",
    "            # count limit\n",
    "            if not fullOverlap and iou < 0.05 and negative_ROIs <= max_negative:\n",
    "                # extract the ROI and then derive the output path to# the negative instance\n",
    "                roi = image[prop_y1:prop_y2, prop_x1:prop_x2]\n",
    "                filename = \"{}.png\".format(total_negative)\n",
    "                outputPath = os.path.join(*[negative_path,filename])\n",
    "                # increment the negative counters\n",
    "                negative_ROIs += 1\n",
    "                total_negative += 1\n",
    "            # check to see if both the ROI and output path are valid\n",
    "            if roi is not None and outputPath is not None:\n",
    "                # resize the ROI to the input dimensions of the CNN\n",
    "                # that we'll be fine-tuning, then write the ROI to# disk\n",
    "                roi = cv2.resize(roi, input_dims,interpolation=cv2.INTER_CUBIC)\n",
    "                cv2.imwrite(outputPath, roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab96586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the dataset manually as many negative samples are in the positive dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223feecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# once we have dataset we will fine tune models to build racoon/no-raccoon classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8b1c89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lables_to_class={\"raccoon\":0,\"no_raccoon\":1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffd4580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "labels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42f85582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(raccoon_path,no_raccoon_path):\n",
    "    data=[]\n",
    "    labels=[]\n",
    "    for dir_ in [raccoon_path,no_raccoon_path]:\n",
    "        label=0\n",
    "        if \"no_raccoon\" in dir_:\n",
    "            label=1\n",
    "        for img_name in os.listdir(dir_):\n",
    "            \n",
    "            img_path=os.path.join(dir_,img_name)\n",
    "            img=cv2.imread(img_path)\n",
    "            img=np.resize(img,(224,224))\n",
    "            data.append(img)\n",
    "            labels.append(label)\n",
    "    return np.array(data),np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75744cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "raccoon_tr_path = os.path.join(*[prepared_data_path, \"raccoon\"])\n",
    "no_raccoon_tr_path = os.path.join(*[prepared_data_path, \"no_raccoon\"])\n",
    "raccoon_te_path = os.path.join(*[prepared_data_path, \"raccoon_test\"])\n",
    "no_raccoon_te_path = os.path.join(*[prepared_data_path, \"no_raccoon_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e04264ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr,y_tr=get_data(raccoon_tr_path ,no_raccoon_tr_path )\n",
    "x_te,y_te=get_data(raccoon_te_path ,no_raccoon_te_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fbcb766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2285, 224, 224)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd22ff4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(590, 224, 224)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3f5b220",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = to_categorical(y_tr)\n",
    "y_te = to_categorical(y_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "373bd7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0a284dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.15,\n",
    "\twidth_shift_range=0.2,\n",
    "\theight_shift_range=0.2,\n",
    "\tshear_range=0.15,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bf74f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      " 303104/9406464 [..............................] - ETA: 10:43"
     ]
    }
   ],
   "source": [
    "# load the MobileNetV2 network, ensuring the head FC layer sets are\n",
    "# left off\n",
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "\tinput_tensor=Input(shape=(224, 224, 3)))\n",
    "# construct the head of the model that will be placed on top of the\n",
    "# the base model\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "# loop over all layers in the base model and freeze them so they will\n",
    "# *not* be updated during the first training process\n",
    "for layer in baseModel.layers:\n",
    "\tlayer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258c1e33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
